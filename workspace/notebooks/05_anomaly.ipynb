{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from src.models.predictor import TrollPredictor\n",
    "\n",
    "from src.data_tools.czech_data_tools import load_czech_media_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictor from Checkpoint\n",
    "# predictor = TrollPredictor(\n",
    "#     model_path= \"checkpoints/best_model.pt\",\n",
    "#     comments_per_user=10,\n",
    "#     max_length=64\n",
    "# )\n",
    "\n",
    "# Predictor from Hugging Face pretrained model\n",
    "predictor = TrollPredictor(\n",
    "    model_name = \"ufal/robeczech-base\",\n",
    "    comments_per_user=10,\n",
    "    max_length=96\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files:   0%|                                                                            | 0/124 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files: 100%|██████████████████████████████████████████████████████████████████| 124/124 [00:10<00:00, 11.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 845764 comments from 66590 unique authors\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path('data')\n",
    "czech_comments = load_czech_media_data(str(DATA_DIR / 'MediaSource'))\n",
    "print(f\"Loaded {len(czech_comments)} comments from {czech_comments['author'].nunique()} unique authors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'raw_text', 'author', 'timestamp', 'article_title', 'url',\n",
       "       'article_id', 'sentiment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "czech_comments.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Account Embeddings\n",
    "account_embeddings = []\n",
    "account_labels = []\n",
    "\n",
    "authors = list(czech_comments[\"author\"].unique())[:10000]\n",
    "\n",
    "# Filter authors with at least 10 comments\n",
    "authors = [author for author, count in czech_comments[\"author\"].value_counts().items() if count >= 10]\n",
    "\n",
    "# Ensure the model is on the correct device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "predictor.model.to(device)\n",
    "\n",
    "for author in authors:\n",
    "    group = czech_comments[czech_comments[\"author\"] == author]\n",
    "\n",
    "\n",
    "    comments = group[\"text\"].tolist()\n",
    "\n",
    "    # Pad or trim to predictor.comments_per_user:\n",
    "    if len(comments) >= predictor.comments_per_user:\n",
    "        comments = comments[:predictor.comments_per_user]\n",
    "    else:\n",
    "        comments = (comments * ((predictor.comments_per_user // len(comments)) + 1))[:predictor.comments_per_user]\n",
    "\n",
    "    # Tokenize\n",
    "    encoded = predictor.tokenizer(comments, padding=True, truncation=True, max_length=predictor.max_length, return_tensors=\"pt\")\n",
    "\n",
    "    # Move input tensors to the same device as the model\n",
    "    encoded = {key: tensor.to(device) for key, tensor in encoded.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Pass the tokenized inputs to the TrollDetector model\n",
    "        outputs = predictor.model(\n",
    "            input_ids=encoded[\"input_ids\"],\n",
    "            attention_mask=encoded[\"attention_mask\"],\n",
    "            tweets_per_account=predictor.comments_per_user\n",
    "        )\n",
    "        account_emb = outputs[\"account_embedding\"].cpu().numpy()\n",
    "        \n",
    "\n",
    "    # Aggregate comments into account embedding\n",
    "    account_embeddings.append(account_emb)\n",
    "\n",
    "account_embeddings = np.vstack(account_embeddings)\n",
    "account_labels = np.array(account_labels) if account_labels else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit isolation forest\n",
    "clf = IsolationForest(contamination=0.1, random_state=42)\n",
    "clf.fit(account_embeddings)\n",
    "scores = -clf.decision_function(account_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mROC-AUC:\u001b[39m\u001b[38;5;124m\"\u001b[39m, roc_auc_score(account_labels, scores))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Save Anomaly Scores\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauthor\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mauthors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43manomaly_score\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manomaly_scores.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.11/site-packages/pandas/core/frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    774\u001b[0m     )\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m~/miniconda/lib/python3.11/site-packages/pandas/core/internals/construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.11/site-packages/pandas/core/internals/construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.11/site-packages/pandas/core/internals/construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    675\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    682\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "if account_labels is not None:\n",
    "    print(\"ROC-AUC:\", roc_auc_score(account_labels, scores))\n",
    "\n",
    "# Save Anomaly Scores\n",
    "pd.DataFrame({\n",
    "    \"author\": authors,\n",
    "    \"anomaly_score\": scores\n",
    "}).to_csv(\"anomaly_scores.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "tsne_embs = tsne.fit_transform(account_embeddings)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "if account_labels is not None:\n",
    "    plt.scatter(tsne_embs[:, 0], tsne_embs[:, 1], c=account_labels, cmap=\"coolwarm\", alpha=0.7)\n",
    "    plt.colorbar(label=\"Troll label\")\n",
    "else:\n",
    "    plt.scatter(tsne_embs[:, 0], tsne_embs[:, 1], c=scores, cmap=\"viridis\", alpha=0.7)\n",
    "    plt.colorbar(label=\"Anomaly Score\")\n",
    "plt.title(\"t-SNE Visualization of Account Embeddings\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Show Top Anomalous Authors ---\n",
    "results_df = pd.DataFrame({\"author\": authors,\n",
    "    \"anomaly_score\": scores\n",
    "}).sort_values(\"anomaly_score\", ascending=False)\n",
    "\n",
    "# Filter authors with at least 5 comments\n",
    "author_comment_counts = czech_comments[\"author\"].value_counts()\n",
    "authors_with_min_comments = author_comment_counts[author_comment_counts >= 5].index\n",
    "\n",
    "\n",
    "# Filter results_df to include only authors with at least 5 comments\n",
    "results_df = results_df[results_df[\"author\"].isin(authors_with_min_comments)]\n",
    "\n",
    "print(\"\\nTop 10 most anomalous authors:\")\n",
    "print(results_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the distribution of anomaly scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(results_df[\"anomaly_score\"], bins=50, color=\"skyblue\", alpha=0.7, edgecolor=\"black\")\n",
    "plt.title(\"Distribution of Anomaly Scores\", fontsize=16)\n",
    "plt.xlabel(\"Anomaly Score\", fontsize=14)\n",
    "plt.ylabel(\"Frequency\", fontsize=14)\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Sample Comments from Top Anomalous Authors\n",
    "top_authors = results_df.head(10)[\"author\"].tolist()\n",
    "\n",
    "print(\"\\nSample comments from top anomalous authors:\\n\")\n",
    "for author in top_authors:\n",
    "    author_comments = czech_comments[czech_comments[\"author\"] == author][\"text\"].tolist()[:5]\n",
    "    print(f\"Author: {author}\")\n",
    "    for comment in author_comments:\n",
    "        print(f\" - {comment}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Sample Comments from Least Anomalous Authors \n",
    "least_anomalous_authors = results_df.tail(10)[\"author\"].tolist()\n",
    "\n",
    "print(\"\\nSample comments from least anomalous authors:\\n\")\n",
    "for author in least_anomalous_authors:\n",
    "    author_comments = czech_comments[czech_comments[\"author\"] == author][\"text\"].tolist()[:5]\n",
    "    print(f\"Author: {author}\")\n",
    "    for comment in author_comments:\n",
    "        print(f\" - {comment}\")\n",
    "    print(\"-\" * 40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
