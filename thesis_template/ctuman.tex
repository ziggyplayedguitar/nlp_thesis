% arara: pdflatex: { synctex: yes }
% arara: makeindex: { style: ctuthesis }
%% arara: bibtex

%\listfiles


%\PassOptionsToPackage{cp1250}{inputenc}

% The class takes all the key=value arguments that \ctusetup does,
% and couple more: draft and oneside
\documentclass[twoside]{ctuthesis}

\usepackage{natbib}

\makeatletter
\edef\mytoday{\expandafter\@gobbletwo\the\year\ifnum\month<10 0\fi\the\month\ifnum\day<10 0\fi\the\day}
\makeatother

% LaTeX logo with better kerning in sf bf font
\makeatletter
\newcommand\LaTeX@lmss@bx{L\kern-.33em{\sbox\z@ T\vboxto\ht\z@{\hbox{\check@mathfonts\fontsize\sf@size\z@\math@fontsfalse\selectfont A}\vss}}\kern-.15em\TeX}
\DeclareRobustCommand\myLaTeX{%
	\ifcsname LaTeX@\f@family @\f@series\endcsname
		\csname LaTeX@\f@family @\f@series\endcsname
	\else
		\LaTeX
	\fi
}

\ctusetup{
%	preprint = {\ctuverlog \\ ctuman \mytoday},
	mainlanguage = english,
%	titlelanguage = english,
%	otherlanguages = {czech},
	% title-czech = {Manuál ke třídě ctuthesis pro {\myLaTeX}},
	title-english = {NLP Trolls},
	doctype-english = {Bachelor thesis},
%	xfaculty = F4,
%	department-czech = {Katedra matematiky},
%	department-english = {Department of Mathematics},
	author = {Luka Peraica },
	supervisor = {Ing. Radek Mařík, CSc.},
%	supervisor-address = {Ústav X, \\ Uliční 5, \\ Praha 99},
	keywords-czech = {manuál, závěrečnná práce, \LaTeX},
	keywords-english = {manual, degree project, \LaTeX},
	day = 16,
	month = 4,
	year = 2024,
%	list-of-figures = false,
%	list-of-tables = false,
%	monochrome = true,
%	savetoner = true,
	pkg-listings = true,
	ctulstbg = none,
%	layout-short = true,
%	pkg-hyperref = false,
}

\ctuprocess

% Theorem declarations, this is the reasonable default, anybody can do what they wish.
% If you prefer theorems in italics rather than slanted, use \theoremstyle{plainit}
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[chapter]
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{conjecture}[theorem]{Conjecture}

\theoremstyle{note}
\newtheorem*{remark*}{Remark}
\newtheorem{remark}[theorem]{Remark}

% Marginpars used as navigation aids.
\usepackage{mparhack}

\newcommand\indexmp[1]{{\sffamily\bfseries#1}}

\ExplSyntaxOn
\cs_new:Nn \ctuman_domarginpar:n {
	\marginpar
	[ \raggedleft \footnotesize \sffamily #1 ]
	{ \raggedright \footnotesize \sffamily #1 }
}
\cs_generate_variant:Nn \ctuman_domarginpar:n { x }
\DeclareDocumentCommand\ctump{m}{
	\clist_set:Nn \ctuman_temp_clist { #1 }
	\ctuman_domarginpar:x { \clist_use:Nnnn \ctuman_temp_clist { \\ } { \\ } { \\ } }
	\clist_map_inline:Nn \ctuman_temp_clist { \index{##1|indexmp} }
	\ignorespaces
}
\ExplSyntaxOff

% Abstract in Czech
\begin{abstract-czech}
V záplavě mnoha zdrojů a množství mediálních zpráv není jednoduché se zorientovat i pro profesionální mediální analytiky. 
Výrazem demokracie je i možnost se ke zprávám vyjadřovat a tříbit si názory v diskusních příspěvcích dílčích zpráv. 
Diskuse však vytváří prostor i pro osoby, jejichž cílem je z rozmanitých důvodu diskuse narušovat a překrucovat. 
Cílem práce je vytvořit komponenty systému, který umožní sledovat linie vývoje tématu a identifikovat příspěvky narušitelů, 
tzv. trollů.\end{abstract-czech}

% Abstract in English
\begin{abstract-english}
	
\end{abstract-english}

% Acknowledgements / Podekovani
\begin{thanks}
	We thank the CTU in Prague for being a~very good \emph{alma mater}.
\end{thanks}

% Declaration / Prohlaseni
\begin{declaration}
	I declare that this work is all my own work and I have cited all sources I have
	used in the bibliography.

\medskip

	Prague, \monthinlanguage{title} \ctufield{day}, \ctufield{year}

\vspace*{2cm}

	Prohlašuji, že jsem předloženou práci vypracoval samostatně, a že jsem uvedl veškerou použitou literaturu.

\medskip

	V Praze, \ctufield{day}.~\monthinlanguage{second}~\ctufield{year}
\end{declaration}

\usepackage{url}

\usepackage{tabularx,array}

\usepackage{mathtools,amssymb}

% A savebox for typesetting listings in the titles
\newsavebox{\myboxa}

%\newcommand*\symbO{$\color{red}\bowtie$}
\newcommand*\symbO{\raisebox{0.5\height}{\scalebox{0.7}{\color{red}${\vartriangleright}\mkern-6mu{\vartriangleleft}$}}}
\newcommand*\symbM{\raisebox{0.5\height}{\scalebox{0.7}{\color{red}${\blacktriangleright}\mkern-6mu{\blacktriangleleft}$}}}
\newcommand*\itemO{\item\leavevmode\kern-0.33em\symbO}
\newcommand*\itemM{\item\leavevmode\kern-0.33em\symbM}



\begin{document}

% We actually don't want inline listings to have a background color
\renewcommand \ctulstsep{0pt}

% \ctuclsname for typesetting the class' name
\newcommand\ctuclsname{\leavevmode\unhcopy\ctuclsnamebox}
\newsavebox\ctuclsnamebox
\begin{lrbox}{\ctuclsnamebox}
\ctulst!ctuthesis!
\end{lrbox}

\maketitle

% ========================================== CHAPTER 1 INTRODUCTION ==============================
\chapter{Introduction}

\section{Problem Statement}
\par
The way humans communicate and interact has changed dramatically in the age of the internet. Social media sites, forums and comment sections have become primary spaces for people to share ideas, debate issues and engage in public discourse. These online discussion platforms allow individual from different backgrounds to express their opinions and be part of conversations that shape public perspective more easily than ever before. However, while online discussions create opportunities for connecting people and sharing information, they also come with diverse challenges like the spread of misinformation, polarization and disruptive behavior.\par

Given these challenges, it becomes crucial to understand how online discourse shapes public opinion. In today’s flood of diverse media sources and information, even professional media analysts find it challenging to navigate and filter reliable content. A key aspect of democracy is the ability to express opinions and refine perspectives through discussions. Social media platforms like Twitter, Facebook and Reddit have a powerful influence on public opinion and can significantly shape political outcomes~\cite{Bennett2012DigitalMedia}. However, these online discussions also create opportunities for individuals whose goal is to disrupt and manipulate conversations for various reasons.\par

\section{Defining Online Trolling}
To address the negative consequences of disruptive online behavior mentioned earlier, it is important to define one its most prevalent forms: online trolling. Online trolling is a deliberate act intended to provoke, deceive, or disrupt online conversations. According to Coles and West~\cite{Coles2016}, trolling involves actions meant to annoy, frustrate, or engage others in pointless disputes. Similarly, Golf-Papez and Veer~\cite{GolfPapez2017DontFeedTheTroll} define trolling as ``deliberate, deceptive, and mischievous attempts to provoke reactions from other users''.\par
The term ``trolling'' was originally borrowed from fishing slang, where it referred to dragging a baited line through the water to catch fish. In the online context, the term seems to have first been used  in the 1990s on the USET discussion system where some users would deliberately create posts designed to trigger angry corrections from newbie users who weren't aware of such pracitces.\par

There is a second definition for the word ``troll'', which is also quite relevant to the perception of online trolls and perhaps for most people the first connotation that comes to mind. This definition refers to a troll as a large, ugly creature from folklore, often depicted as a giant or ogre. The word ``troll'' is derived from the Old Norse word ``troll'', which means ``giant'' or ``ogre''. In this context, the term evokes an image of a monstrous being that lurks in the shadows, waiting to pounce on unsuspecting victims. And while the term trolling originated from the early bait posts, related to the fishing term, over time the the character and label of the ``troll'' developed, which is more closly related to the folklore definition. This shift in meaning reflects the evolution of online trolling from simple baiting to a more malicious character lurking on the internet.\cite{Demsar2021}\par

While some forms of trolling may seem harmless or playful, others can escalate into targeted harassment, misinformation campaigns, and efforts to manipulate public opinion.\par
People engage in trolling for various reasons, from simply seeking amusement from the activity to pushing political or ideological agendas. Research has shown that certain psychological factors also contribute to the online trolling phenomena, such as the ``online disinhibition effect''. This theory suggests that people act more aggressively online because they feel anonymous and free from real-world consequences~\cite{Suler2004}. Additionally, studies indicate that personality traits like psychopathy, narcissism, and Machiavellianism are often linked to trolling behavior~\cite{Buckels2014TrollsWantToHaveFun}.\par

Beyond individual psychology trolls also exploit broader technological factors, particularly social media algorithms that prioritize engagement. Effectively playing into the algorithm allows them to more easily and effectively spread divisive content and manipulate conversations~\cite{GolfPapez2017DontFeedTheTroll}.

\section{Impacts of Trolling}
Trolling negatively affects honest individuals involved in online discussions. Those targeted by trolls often experience stress, anxiety, and frustration, which can discourage them from participating in online discourse. Repeated exposure to trolling can drive individuals away from digital platforms, silencing voices that would otherwise contribute to meaningful discussions. This type of behavior not only harms individual well-being but also degrades the quality of discussions. As user trust is eroded and people become more skeptical of digital interactions a toxic environment is created where constructive engagement becomes difficult~\cite{GolfPapez2017DontFeedTheTroll}.\par

On a larger scale trolling has significant consequences, particularly when it is used as a toll for political manipulation. State-sponsored troll campaigns have been used to spread propaganda, influence elections, and undermine public trust in media~\cite{Bradshaw2017TroopsTrolls}. One of the most well-known exaples is the Russian \textit{Internet Research Agency} (IRA), which ran large-scale trolling operations during the 2016 U.S. presidential election between Hillary Clinton and Donald Trump. These trolls used fake accounts to post divisive content and manipulate public discourse~\cite{Linvill2020IRATrolls}. Similar use of trolling in political campaigns and foreign influence operations has been documented across the world, demonstrating the severity and importance of addressing the issue.\par

This thesis aims to identify and analyze behavior of trolls in online discussions. Specifically, it will explore different NLP techniques for troll detection, including stylometry, topic modeling, deep learning, and transformer models. The goal is to idenitfy harfmul contributions and contributors to online discussions and to explore possibilites for further research in thsi area.\par

% ========================================== CHAPTER 2 NLP =====================
\chapter{Natural Language Processing}
Given the impact of disruptive trolls on online discourse and society at large, research efforts have focused on developing techniques to better understand, detect and mitigate their activity. This chapter explores the methods used to analyze and identify trolling behavior particularly through Natural Language Processing (NLP). It covers key approaches such as stylometry, sentiment analysis, and topic modelling.\par

\section{Stylometry}
Stylometry is the discipline of analyzing writing style to uncover patterns, identify authors, and extract meaningful details from texts~\cite{Mosteller1964Federalist}~\cite{Pascucci2020Misogyny}. The term was introduced in 1890 by the Polish philosopher Wincenty Lutosławski, who applied it to analyze Plato's works~\cite{Lutoslawski1898}. In the context of this thesis,  stylometry involves the use of automated techniques to analyze linguistic traits that distinguish authors based on their unique writing patterns.\par
The underlying assumption in stylometry is that an author’s choices are influenced by sociological factors, such as age, gender, and education level, as well as psychological factors, like personality and native language proficiency~\cite{Daelemans2013Explanation}. This assumption can be extended to groups of authors, especially those who may share common objectives or adhere to specific guidelines, such as state-sponsored trolls, or display similar behavioral patterns as seen among ordinary trolls. These individual or collective choices can manifest as identifiable stylistic features within texts, which computational models can analyze to detect trolling behavior.
Stylometric analyses typically examine lexical choices like vocabulary richness, syntactic elements including sentence structure and grammatical complexity~\cite{Sari2018Features}, and semantic dimensions, such as sentiment and thematic consistency~\cite{PerezRosas2018Stylometry}. Extracting and evaluating these features allows machine learning classifiers to differentiate between regular users and trolls based on their distinctive linguistic signatures.\par

\section{Topic Detection}
Topic detection is another essential NLP technique used to analyze and interpret corpora of text. It identifies main topics in large amounts of text and groups conversations based on these topics. This can help us understand conversation patterns and recognize signs of disruptive behavior. Trolls often move discussions off-topic, introduce controversial subjects, or focus repeatedly on divisive issues. We can analyze the kinds of topics a user engages with and how they behave within those topics to find clues about their intentions and their role in discussions.\par

\section{Transformer Models}
%TODO: Vysvletit vice do hlobky? -attention, encoder-decoder, pre-training etc., matika?
In recent years, Transformer models have emerged as the state-of-the-art approach for a wide range of NLP tasks. Introduced by First introduced by Vaswani et al. in 2017~\cite{Vaswani2017}, Transformers offer a new way for machines to understand and generate language. Unlike earlier methods, they are designed to efficiently capture relationships and patterns within text, even over long passages. Their ability to handle large amounts of data and to adapt to complex language structures has made them a key tool in modern NLP applications. In this section, we will introduce the basic ideas behind Transformer models.\par

The key innovation of Transformer models is the use of self-attention mechanisms. Instead of processing text word by word like earlier models, Transformers can consider all words in a sentence at once, deciding how much attention each word should pay to others. This allows the model to capture complex patterns and dependencies across long texts, making it very powerful for understanding the both the context and meaning of language.\par

An important reason for the success of Transformer models is that they are typically very large models pre-trained on massive datasets. Many of these datasets are multilingual, meaning that the models learn from several languages at once. As a result, we can often use the same embedding space for different languages, and the knowledge gained in one language can transfer to some extent to others. This makes pre-trained Transformers especially valuable when dealing with multilingual or cross-lingual data.\par

One of the most influential Transformer-based models for natural language understanding is BERT (Bidirectional Encoder Representations from Transformers). Introduced by Devlin et al. in 2018~\cite{Devlin2018}, BERT builds on the Transformer encoder architecture and is pre-trained on large text corpora using masked language modeling and next sentence prediction tasks. Unlike traditional language models that read text from left to right, BERT is deeply bidirectional, meaning it learns information from both the left and right context at the same time. This bidirectional training allows BERT to capture richer information about language, making it highly effective for downstream tasks like text classification, question answering, and sentiment analysis. In this thesis, we will leverage pre-trained Transformer such models as BERT and try to fine tune them for the troll detection task.\par

% ========================================== CHAPTER 3 RELATED METHODS =====================
\chapter{Related Methods}
This chapter provides an overview of the methods and techniques used in the field of troll detection. We will explore various approaches, including stylometry, sentiment analysis, and topic modeling, which are commonly employed to analyze online discussions and identify trolling behavior. Each section will discuss the principles behind these methods, their applications in troll detection, and their strengths and limitations.\par

\subsection{Stylometry}
An example of stylometry applied to fake news detection is presented in the work of Pérez-Rosas et al.~\cite{PerezRosas2018Stylometry}. They used a variety of stylometric features, including n-grams, punctuation frequency, readability metrics and syntactic features. They also incorporated psycholingustic features extracted from the LIWC lexicon which categorize words into various psychological categories. LIWC features capture psychological aspets of a text such as emotional tone or cognitive processes, potentially revealing underlying psychological differences between fake and legitimate news writers. A linear SVM classifier was trained on these features to differentiate between fake and legitimate news articles. Their results showed that stylometric features can be effective for the task, achieving accuracies of up to 76\% which outperformed two human annotators. The analysis uncovered distinct linguistic patterns in fake news, such as increased use of social and positive words, a focus on present and future actions, and a higher prevalence of adverbs, verbs, and punctuation marks. 

In another paper, Kandasamy et at.~\cite{Kandasamy2021COVID} proposed a deep learning framework for sentiment analysis of COVID-19-related tweets. Their approach used an N-gram stacked autoencoder to capture text features. These features were then processed by a set of classifiers—decision trees, support vector machines, random forests, and k‑nearest neighbors. The highest accuracy was achieved using an ensemble model that combined all of these classifiers, this method achieved an accuracy of 87,75\%. The study demonstrated that using n‑grams greatly improved the classification of negative sentiment, an emotion that was prevalent during the pandemic.

Though stylometry has proven useful for text classification, recent advancements in large language models and their potential for misuse might pose a substantial challenge to its efficacy. As demonstrated by Schuster et al.~\cite{Schuster2020}, stylmoetry may struggle to differentiate between human-written and machine-generated text. In their study they find that while a state-of-the-art stylometry-based classifier could effectively detect the presence of machine-generated text within human-written content, it struggled to discern the truthfulness of the generated text.  For instance, even a single auto-generated sentence within a longer human-written text was easily detectable, but the veracity of that sentence remained largely undecidable.  Additionally, even a relatively weak LM could produce statement inversions that evaded detection by the stylometry-based model.

%\section{Sentiment Analysis}
%Sentiment analysis is a subfield of natural language processing that focuses on identifying and quantifying the emotional tone behind textual data. By analyzing words and their context  it aims to classify text according to its polarity - positive, negative or neutral.\par

%\subsection{Word2Vec}
%Word2Vec is a powerful word embedding technique used in NLP to represent words as dense numerical vectors~\cite{Mikolov2013Word2vec}. These vectors capture semantic relationships between words, allowing for meaningful comparisons and analysis. Word2Vec utilizes a shallow neural network to learn word embeddings from a large corpus of text, where the weights of the trained model serve as the embedding vectors. This technique has gained popularity in various NLP tasks, including   sentiment analysis.

\subsection{Sentiment Analysis}
Jiang et al.~\cite{Jiang2021Sentiment} explored the use of sentiment analysis for troll detection on the chinese social media platform Weibo.  They employed a Word2Vec model trained on a dataset of Weibo comments to generate word embeddings. These embeddings were then used to calculate sentiment scores, incorporating features such as happiness, anger, disgust, and fear. The sentiment was used along with meta features such as the location of a comment in a thread or its like count to train XGBoost and SVM models for the troll detection task. The approach proved effective with the XGBoost model achieving an accuracy of up to 89\% and SVM up to 87\%.\par
In another paper leveraging sentiment analysis Machova et al.~\cite{Machova2022Comparison} explored the detection of suspicious reviewers in online discussions, specifically focusing on trolls. Their lexicon-based approach analyzed the polarity of comments to identify trolls. It was based on the tendency of trolls to express extreme opinions that oppose the general sentiment of the discussion. They compared this approach with a Convolutional Neural Network (CNN) model, finding that both performed similarly on text data, achieving accuracies of 0.95 and 0.959, respectively.  The study also employed machine learning methods, such as Support Vector Machines (SVM), using non-textual features like comment karma, likes, and dislikes. With the SVM model they achieved an accuracy of 0.986.

\section{Topic Detection}

%Topic modeling techniques are used to automatically identify hidden thematic structures within a collection of texts. In the context of online discussions, these methods can help uncover what people are talking about, identify dominant issues, and track the evolution of discussions over time. When dealing with large volumes of unstructured text, such as social media or news comment sections, topic modeling becomes a powerful tool for surfacing patterns without relying on predefined categories.

%\subsection{LDA}
%One of the most widely used topic modeling methods is Latent Dirichlet Allocation (LDA)~\cite{Blei2001LDA}. LDA is a probabilistic model that identifies latent topics in documents based on word co-occurrence patterns. It assumes that each document is a mixture of topics, and each topic is a distribution over words. By analyzing the distribution of these word co-occurrence in text, LDA tries to infer a topic for each document.\par
%LDA has been successfully used to analyze coordinated online activity, including troll campaigns. For example, Golino et al. ~\cite{Golino2022Elections} used LDA to uncover dominant themes in troll tweets during the 2016 U.S. presidential election, revealing coordinated messaging around divisive political issues. However, despite its popularity, LDA has limitations. It often requires manual tuning of the number of topics, may produce less coherent topic groupings, and struggles with short texts, such as comments or tweets~\cite{Ruediger2022TopicModellingRevisited}.\par

%\subsection{BERTopic}
%BERTopic is a state-of-the-art technique that can be used for dynamic topic modeling. It leverages pre-trained transformer models (e.g., BERT) to convert documents into dense vector representations that capture their semantic meaning. These vector embeddings are then clustered to identify semantically similar documents.
%To make the topics easier to understand, BERTopic uses a method called Class-based TF-IDF, which selects the most relevant words for each group of similar documents. This helps the model form clusters that are not only based on meaning but are also easy to interpret and describe in context~\cite{Grootendorst2022BERTopic}.

%\subsection{EVOC}
%EVOC (Embedding Vector Oriented Clustering) is a tool for quickly clustering high-dimensional text embeddings, making it useful for large datasets.\footnote{\url{https://github.com/TutteInstitute/evoc}} It works well with sentence embeddings from models like BERT or CLIP and can automatically choose the number of clusters, reducing the need for manual tuning.
% TODO GitHub jako citace nebo footnote?

%\subsection{Top2Vec}
%Top2Vec is a state-of-the-art and well-established alternative to traditional topic modeling techniques like LDA. Unlike LDA, where the number of topics needs to be set manually, Top2Vec automatically determines the optimal number of topics. It achieves this by analyzing the density of document clusters in a vector space created using word embeddings. This is advantageous especially with datasets where the exact number of topics is not clear. Additionally, Top2Vec provides a unique topic representation by identifying the most representative documents and phrases for each topic. This representation, allows for a more nuanced understanding of the topics compared to traditional methods that primarily focus on individual words~\cite{Angelov2024}.

% ========================================== CHAPTER 4 PROPOSED METHOD =====================
\chapter{Proposed Method}



% ========================================== CHAPTER 5 EXPERIMENTS ======================
\chapter{Experiments}

\section{Dataset}
The dataset used in this thesis consists of user-generated comments collected from the discussion sections under news articles published on Novinky.cz, one of the largest Czech news portals. Each article on Novinky.cz includes a public comment section where users actively engage in discussions about the content presented. These discussions are often extensive, with some articles attracting hundreds of user comments.\par

In the Czech online media landscape, it is widely recognized that the comment sections on major news sites, particularly on Novinky.cz for example, frequently serve as hotbeds for controversy and emotionally charged discourse. They are often perceived by the public as spaces where individuals express grievances, frustrations, and polarizing viewpoints, sometimes in ways that border on or cross into what could be described as abusive, manipulative or troll like behavior. This cultural context makes Novinky.cz a relevant and interesting setting for exploring how online discussions develop, especially where conversations become heated or emotionally charged.\par

For the purposes of this thesis, a large-scale dataset comprising approximately 350,000 comments posted by around 48,000 users was provided by Newton Media, a prominent media intelligence organization.\par 
% TODO: add time frame of collected data

Each data entry includes the following attributes:
\begin{itemize}
    \item \textbf{Comment content} – the full textual body of the comment.
    
    \item \textbf{Article metadata} – including the title and link to the article under which the comment was posted
    
    \item \textbf{Timestamp} – the date and time when the comment was published.
    
    \item \textbf{Author name} – full author name as collected from the discussion.
    
    \item \textbf{Sentiment label} – a sentiment category assigned by Newton Media, labeled as one of the following: \textit{Neutral}, \textit{Positive}, \textit{Negative}, or \textit{Ambivalent}.
\end{itemize}

A key challenge posed by this dataset is the absence of explicit troll/non-troll labels. Since there is no ground-truth annotation for trolling behavior,  we cannot directly apply supervised classification methods. Because of this, we have to rely on unsupervised or semi-supervised techniques, such as clustering, topic modeling, or anomaly detection, to try to find patterns that may point to trolling based on how the comments are written and their sentiment. The lack of labeled data also makes it difficult to verify the accuracy or effectiveness of any classifications or patterns identified during experimentation. Without labeled data, we cannot easily measure how accurate our models are, and must instead rely on manual checks, indirect indicators, or interpretation of the patterns found\par

\appendix

\printindex

\bibliographystyle{alpha} 
\bibliography{../sources/library.bib}

\end{document}